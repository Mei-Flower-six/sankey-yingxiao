# sankeyyingxiao_streamlit.py
import pandas as pd
import plotly.graph_objects as go
import plotly.utils
import logging
import streamlit as st
from datetime import datetime
import json

# ===================== 1. é¡µé¢é…ç½®å’ŒåŸºç¡€é…ç½® =====================
st.set_page_config(
    page_title="è”ç›Ÿè¥é”€å¹³å°è½¬åŒ–é“¾è·¯åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# é¢œè‰²é…ç½®ï¼ˆæ¯ä¸ªå¹³å°å¯¹åº”ä¸“å±é¢œè‰²ï¼‰
GROUP_COLORS = {
    "çº¢äºº": "#9290E6",
    "çº¢äººåˆä½œæ•°é‡": "#9290E6",
    "æµ‹è¯„ç±»ç½‘ç«™": "#4ECDC4",
    "æµ‹è¯„ç±»ç½‘ç«™åˆä½œæ•°é‡": "#4ECDC4",
    "è”ç›Ÿå®¢": "#45B7D1",
    "è”ç›Ÿå®¢åˆä½œæ•°é‡": "#45B7D1",
    "æŠ˜æ‰£ç½‘ç«™": "#96CEB4",
    "æŠ˜æ‰£ç½‘ç«™åˆä½œæ•°é‡": "#96CEB4",
    "Deals ç½‘ç«™": "#FFA726",
    "Deals ç½‘ç«™åˆä½œæ•°é‡": "#FFA726",
    "Dealsç½‘ç«™": "#FFA726",
    "Dealsç½‘ç«™åˆä½œæ•°é‡": "#FFA726",
    "æ€»æ•°é‡": "#1C363F",
    "æ€»clicks": "#87CEEB",
    "æ€»orders": "#FF6B6B",
    "æ€»sales": "#DDA0DD",
    "é»˜è®¤": "rgba(200, 200, 200, 0.2)"
}

# ===================== 2. è¯»å–Excel+ç”Ÿæˆä¸“å±åˆä½œæ•°é‡é“¾è·¯ =====================
@st.cache_data
def read_excel_and_generate_sankey_data(file_path):
    try:
        df = pd.read_excel(file_path)
        logger.info(f"âœ… æˆåŠŸè¯»å–Excelæ–‡ä»¶ï¼Œå…±{len(df)}è¡Œæ•°æ®")
    except Exception as e:
        logger.error(f"âŒ è¯»å–Excelå¤±è´¥ï¼š{str(e)}")
        st.error(f"âŒ è¯»å–Excelå¤±è´¥ï¼š{str(e)}")
        return [], [], {}

    data_raw = []
    all_nodes = []

    for _, row in df.iterrows():
        platform_type = str(row.get("è”ç›Ÿè¥é”€å¹³å°ç±»å‹", "")).strip()
        coop_count = float(row.get("åˆä½œæ•°é‡", 0)) if pd.notna(row.get("åˆä½œæ•°é‡")) else 0.0
        click_count = float(row.get("æ±‚å’Œé¡¹:Clicks", 0)) if pd.notna(row.get("æ±‚å’Œé¡¹:Clicks")) else 0.0
        order_count = float(row.get("æ±‚å’Œé¡¹:Orders", 0)) if pd.notna(row.get("æ±‚å’Œé¡¹:Orders")) else 0.0
        sales = float(row.get("æ±‚å’Œé¡¹:Sales", 0)) if pd.notna(row.get("æ±‚å’Œé¡¹:Sales")) else 0.0

        if not platform_type or platform_type == "nan":
            continue

        platform_coop_node = f"{platform_type}åˆä½œæ•°é‡"

        # æ”¶é›†æ‰€æœ‰èŠ‚ç‚¹
        current_nodes = [
            platform_type,
            platform_coop_node,
            "æ€»æ•°é‡",
            f"{platform_type}clicks",
            "æ€»clicks",
            f"{platform_type}orders",
            "æ€»orders",
            f"{platform_type}sales",
            "æ€»sales"
        ]
        all_nodes.extend(current_nodes)

        # ç”Ÿæˆ8æ¡é“¾è·¯
        data_raw.append([platform_type, platform_coop_node, coop_count, platform_type])
        data_raw.append([platform_coop_node, "æ€»æ•°é‡", coop_count, platform_type])
        data_raw.append(["æ€»æ•°é‡", f"{platform_type}clicks", click_count, platform_type])
        data_raw.append([f"{platform_type}clicks", "æ€»clicks", click_count, platform_type])
        data_raw.append(["æ€»clicks", f"{platform_type}orders", order_count, platform_type])
        data_raw.append([f"{platform_type}orders", "æ€»orders", order_count, platform_type])
        data_raw.append(["æ€»orders", f"{platform_type}sales", sales, platform_type])
        data_raw.append([f"{platform_type}sales", "æ€»sales", sales, platform_type])

    all_nodes = list(set([node for node in all_nodes if node and str(node) != "nan"]))
    logger.info(f"âœ… ç”Ÿæˆæ¡‘åŸºå›¾æ•°æ®å®Œæˆï¼Œå…±{len(data_raw)}æ¡é“¾è·¯ï¼Œ{len(all_nodes)}ä¸ªèŠ‚ç‚¹")
    
    # è®¡ç®—åŸå§‹çš„æ€»èŠ‚ç‚¹æµå…¥é‡ï¼ˆç”¨äºç™¾åˆ†æ¯”è®¡ç®—ï¼‰
    df_temp = pd.DataFrame(data_raw, columns=["source", "target", "value", "group"])
    df_temp["value"] = pd.to_numeric(df_temp["value"], errors="coerce").fillna(0.0)

    # è®¡ç®—åŸå§‹æ€»æµå…¥
    original_total_incoming = df_temp.groupby("target")["value"].sum().to_dict()

    return data_raw, all_nodes, original_total_incoming

# ===================== 3. åº”ç”¨æ ‡é¢˜ =====================
st.title("ğŸ¤ è”ç›Ÿè¥é”€å¹³å°è½¬åŒ–é“¾è·¯åˆ†æ")
st.markdown("---")

# åˆå§‹åŒ–session state
if 'search_keyword' not in st.session_state:
    st.session_state.search_keyword = ""

# ===================== 4. ä¾§è¾¹æ æ§åˆ¶é¢æ¿ =====================
with st.sidebar:
    st.header("âš™ï¸ æ§åˆ¶é¢æ¿")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=["xlsx", "xls"])
    
    # æœç´¢åŒºåŸŸ
    search_keyword = st.text_input(
        "ğŸ” é“¾è·¯æœç´¢ï¼ˆæ”¯æŒå¹³å°ç±»å‹/èŠ‚ç‚¹å…³é”®è¯ï¼‰",
        value=st.session_state.search_keyword,
        placeholder="è¾“å…¥å…³é”®è¯ï¼ˆå¦‚ï¼šçº¢äººã€è”ç›Ÿå®¢ã€æ€»clicks...ï¼‰",
        help="æ”¯æŒå¹³å°ç±»å‹æˆ–èŠ‚ç‚¹å…³é”®è¯æœç´¢"
    )
    
    # æ›´æ–°session state
    st.session_state.search_keyword = search_keyword
    
    # æ¸…ç©ºæœç´¢æŒ‰é’® - ä¿®å¤APIå¼ƒç”¨è­¦å‘Š
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæœç´¢", type="secondary", use_container_width=True):
            st.session_state.search_keyword = ""
            st.rerun()
    
    with col2:
        if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", type="primary", use_container_width=True):
            st.rerun()
    
    st.markdown("---")
    st.subheader("ğŸ“ ç¼©æ”¾æ§åˆ¶")
    
    # åˆå§‹åŒ–ç¼©æ”¾ç³»æ•°
    if 'coop_scale' not in st.session_state:
        st.session_state.coop_scale = 1.0
    if 'clicks_scale' not in st.session_state:
        st.session_state.clicks_scale = 1.0
    if 'orders_scale' not in st.session_state:
        st.session_state.orders_scale = 1.0
    if 'sales_scale' not in st.session_state:
        st.session_state.sales_scale = 1.0
    
    col1, col2 = st.columns(2)
    with col1:
        st.session_state.coop_scale = st.number_input(
            "åˆä½œæ•°é‡é“¾è·¯ç¼©æ”¾",
            min_value=0.01,
            max_value=10.0,
            value=st.session_state.coop_scale,
            step=0.1,
            help="è°ƒæ•´åˆä½œæ•°é‡é“¾è·¯çš„å®½åº¦"
        )
    
    with col2:
        st.session_state.clicks_scale = st.number_input(
            "Clicksé“¾è·¯ç¼©æ”¾",
            min_value=0.01,
            max_value=10.0,
            value=st.session_state.clicks_scale,
            step=0.1,
            help="è°ƒæ•´Clicksé“¾è·¯çš„å®½åº¦"
        )
    
    col3, col4 = st.columns(2)
    with col3:
        st.session_state.orders_scale = st.number_input(
            "Ordersé“¾è·¯ç¼©æ”¾",
            min_value=0.01,
            max_value=10.0,
            value=st.session_state.orders_scale,
            step=0.1,
            help="è°ƒæ•´Ordersé“¾è·¯çš„å®½åº¦"
        )
    
    with col4:
        st.session_state.sales_scale = st.number_input(
            "Salesé“¾è·¯ç¼©æ”¾",
            min_value=0.01,
            max_value=10.0,
            value=st.session_state.sales_scale,
            step=0.1,
            help="è°ƒæ•´Salesé“¾è·¯çš„å®½åº¦"
        )
    
    st.markdown("---")
    st.info("ğŸ’¡ æç¤ºï¼šé¼ æ ‡æ‚¬åœåœ¨å›¾è¡¨ä¸Šå¯ä»¥æŸ¥çœ‹è¯¦ç»†æ•°æ®")

# ===================== 5. æ•°æ®åˆå§‹åŒ– =====================
# ç¡®å®šExcelæ–‡ä»¶è·¯å¾„
if uploaded_file is not None:
    # å¦‚æœæœ‰ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶
    EXCEL_FILE_PATH = uploaded_file
    st.success(f"ğŸ“‚ å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
else:
    # å¦åˆ™ä½¿ç”¨é»˜è®¤æ–‡ä»¶ï¼ˆæœ¬åœ°æµ‹è¯•æ—¶ï¼‰
    EXCEL_FILE_PATH = "ACCæ´»åŠ¨è¡¨ç°çœ‹ç›˜2026.1.26.xlsx"

# åŠ è½½æ•°æ®
try:
    sankey_data, all_nodes, original_total_incoming = read_excel_and_generate_sankey_data(EXCEL_FILE_PATH)
    df_sankey = pd.DataFrame(sankey_data, columns=["source", "target", "value", "group"])
    df_sankey["value"] = pd.to_numeric(df_sankey["value"], errors="coerce").fillna(0.0)
    
    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
    st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{len(df_sankey)}æ¡è®°å½•")
    
except Exception as e:
    st.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
    st.stop()

# ===================== 6. æ•°æ®ç­›é€‰å’Œå¤„ç†ï¼ˆä¸»é€»è¾‘ï¼‰ =====================
# æ˜¾ç¤ºæ•°æ®æ‘˜è¦
with st.expander("ğŸ“Š æ•°æ®æ‘˜è¦", expanded=False):
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("æ€»é“¾è·¯æ•°", len(df_sankey))
    with col2:
        st.metric("å¹³å°ç±»å‹æ•°", len(df_sankey["group"].unique()))
    with col3:
        total_coop = df_sankey[df_sankey["source"].str.contains("åˆä½œæ•°é‡")]["value"].sum()
        st.metric("æ€»åˆä½œæ•°é‡", f"{total_coop:,.0f}")
    with col4:
        total_sales = df_sankey[df_sankey["target"] == "æ€»sales"]["value"].sum()
        st.metric("æ€»é”€å”®é¢", f"{total_sales:,.2f}")

# æ•°æ®ç­›é€‰
df_filtered = df_sankey.copy()
if st.session_state.search_keyword and st.session_state.search_keyword.strip():
    kw = st.session_state.search_keyword.strip().lower()
    df_filtered = df_filtered[
        df_filtered["source"].str.lower().str.contains(kw) |
        df_filtered["target"].str.lower().str.contains(kw) |
        df_filtered["group"].str.lower().str.contains(kw)
    ]

df_agg = df_filtered.groupby(["source", "target", "group"], as_index=False)["value"].sum()
df_agg = df_agg[df_agg["value"] > 0]

# åŠ¨æ€è¯†åˆ«æ‰€æœ‰å¹³å°ç±»å‹
all_sources_targets = pd.concat([df_agg["source"], df_agg["target"]])
platform_nodes_set = set()
for node in all_sources_targets.unique():
    node_str = str(node)
    if (not node_str.endswith("åˆä½œæ•°é‡") and
        not node_str.endswith("clicks") and
        not node_str.endswith("orders") and
        not node_str.endswith("sales") and
        node_str not in ["æ€»æ•°é‡", "æ€»clicks", "æ€»orders", "æ€»sales"] and
        node_str != "nan" and node_str != ""):
        platform_nodes_set.add(node_str)

platform_nodes = sorted(list(platform_nodes_set))

# èŠ‚ç‚¹æ’åº
coop_nodes = []
click_nodes = []
order_nodes = []
sales_nodes = []
total_nodes = []

for platform in platform_nodes:
    coop_node = f"{platform}åˆä½œæ•°é‡"
    if coop_node in df_agg["source"].values or coop_node in df_agg["target"].values:
        coop_nodes.append(coop_node)

    click_node = f"{platform}clicks"
    if click_node in df_agg["source"].values or click_node in df_agg["target"].values:
        click_nodes.append(click_node)

    order_node = f"{platform}orders"
    if order_node in df_agg["source"].values or order_node in df_agg["target"].values:
        order_nodes.append(order_node)

    sales_node = f"{platform}sales"
    if sales_node in df_agg["source"].values or sales_node in df_agg["target"].values:
        sales_nodes.append(sales_node)

# æ€»èŠ‚ç‚¹
for total_node in ["æ€»æ•°é‡", "æ€»clicks", "æ€»orders", "æ€»sales"]:
    if total_node in df_agg["source"].values or total_node in df_agg["target"].values:
        total_nodes.append(total_node)

# æ„å»ºèŠ‚ç‚¹åˆ—è¡¨
all_nodes_sorted = platform_nodes + coop_nodes + ["æ€»æ•°é‡"] + click_nodes + ["æ€»clicks"] + order_nodes + ["æ€»orders"] + sales_nodes + ["æ€»sales"]

# æ¸…ç†èŠ‚ç‚¹
all_nodes_sorted = [str(node).strip() for node in all_nodes_sorted if node and str(node).strip() and str(node) != "nan"]
all_nodes_sorted = list(dict.fromkeys(all_nodes_sorted))

# åˆ›å»ºèŠ‚ç‚¹IDæ˜ å°„
node_id_map = {node: idx for idx, node in enumerate(all_nodes_sorted)}

# èŠ‚ç‚¹ç»Ÿè®¡å’Œå æ¯”è®¡ç®—
original_total_node_values = {
    "æ€»æ•°é‡": original_total_incoming.get("æ€»æ•°é‡", 0),
    "æ€»clicks": original_total_incoming.get("æ€»clicks", 0),
    "æ€»orders": original_total_incoming.get("æ€»orders", 0),
    "æ€»sales": original_total_incoming.get("æ€»sales", 0)
}

filtered_total_incoming = df_agg.groupby("target")["value"].sum().to_dict()
filtered_total_outgoing = df_agg.groupby("source")["value"].sum().to_dict()

node_customdata = []
for node in all_nodes_sorted:
    incoming = filtered_total_incoming.get(node, 0)
    outgoing = filtered_total_outgoing.get(node, 0)

    # è®¡ç®—å æ¯”ï¼ˆä½¿ç”¨åŸå§‹æ€»é‡ï¼‰
    ratio = ""
    if node == "æ€»æ•°é‡" and original_total_node_values["æ€»æ•°é‡"] > 0:
        ratio = f"æ€»åˆä½œæ•°é‡ï¼š{original_total_node_values['æ€»æ•°é‡']:.0f}"
    elif node == "æ€»clicks" and original_total_node_values["æ€»clicks"] > 0:
        ratio = f"æ€»Clicksï¼š{original_total_node_values['æ€»clicks']:.0f}"
    elif node == "æ€»orders" and original_total_node_values["æ€»orders"] > 0:
        ratio = f"æ€»Ordersï¼š{original_total_node_values['æ€»orders']:.0f}"
    elif node == "æ€»sales" and original_total_node_values["æ€»sales"] > 0:
        ratio = f"æ€»Salesï¼š{original_total_node_values['æ€»sales']:.0f}"
    elif "åˆä½œæ•°é‡" in node and original_total_node_values["æ€»æ•°é‡"] > 0:
        ratio = f"å æ€»æ•°é‡ï¼š{(outgoing / original_total_node_values['æ€»æ•°é‡'] * 100):.2f}%"
    elif "clicks" in node and node != "æ€»clicks" and original_total_node_values["æ€»clicks"] > 0:
        ratio = f"å æ€»clicksï¼š{(outgoing / original_total_node_values['æ€»clicks'] * 100):.2f}%"
    elif "orders" in node and node != "æ€»orders" and original_total_node_values["æ€»orders"] > 0:
        ratio = f"å æ€»ordersï¼š{(outgoing / original_total_node_values['æ€»orders'] * 100):.2f}%"
    elif "sales" in node and node != "æ€»sales" and original_total_node_values["æ€»sales"] > 0:
        ratio = f"å æ€»salesï¼š{(outgoing / original_total_node_values['æ€»sales'] * 100):.2f}%"

    node_customdata.append((incoming, outgoing, ratio))

# åŒ¹é…æœç´¢å…³é”®è¯
matched_platforms = []
if st.session_state.search_keyword and st.session_state.search_keyword.strip():
    kw = st.session_state.search_keyword.strip().lower()
    matched_platforms = [p for p in platform_nodes if kw in p.lower()]

matched_nodes = []
for platform in matched_platforms:
    matched_nodes.extend([
        platform,
        f"{platform}åˆä½œæ•°é‡",
        f"{platform}clicks",
        f"{platform}orders",
        f"{platform}sales"
    ])

# ç”Ÿæˆé“¾è·¯æ•°æ®
link_sources = []
link_targets = []
link_values = []
link_colors = []
link_customdata = []

for _, row in df_agg.iterrows():
    source = row["source"]
    target = row["target"]
    original_val = row["value"]
    group = row["group"]

    # æ£€æŸ¥sourceå’Œtargetæ˜¯å¦åœ¨node_id_mapä¸­
    source_str = str(source)
    target_str = str(target)
    if source_str not in node_id_map or target_str not in node_id_map:
        continue

    # åˆ¤æ–­å±äºå“ªä¸ªé˜¶æ®µï¼Œåº”ç”¨å¯¹åº”ç¼©æ”¾ç³»æ•°
    if "åˆä½œæ•°é‡" in target_str or "åˆä½œæ•°é‡" in source_str:
        scale_factor = st.session_state.coop_scale
    elif "clicks" in target_str or "clicks" in source_str:
        scale_factor = st.session_state.clicks_scale
    elif "orders" in target_str or "orders" in source_str:
        scale_factor = st.session_state.orders_scale
    elif "sales" in target_str or "sales" in source_str:
        scale_factor = st.session_state.sales_scale
    else:
        scale_factor = 1.0

    # æ£€æŸ¥æ˜¯å¦åŒ¹é…æœç´¢
    is_matched = group in matched_platforms
    final_val = original_val * scale_factor
    if not is_matched and st.session_state.search_keyword and st.session_state.search_keyword.strip():
        final_val = final_val * 0.05

    # è®¡ç®—é“¾è·¯ç™¾åˆ†æ¯”ï¼ˆä½¿ç”¨åŸå§‹æ€»æµå…¥æ•°æ®ï¼‰
    target_total = original_total_incoming.get(target_str, 1)
    ratio = (original_val / target_total * 100) if target_total > 0 else 0

    # ç¡®å®šé¢œè‰²
    if is_matched:
        final_color = GROUP_COLORS.get(group, GROUP_COLORS.get(source_str, GROUP_COLORS["é»˜è®¤"]))
    elif st.session_state.search_keyword and st.session_state.search_keyword.strip():
        final_color = "rgba(200, 200, 200, 0.2)"
    else:
        final_color = GROUP_COLORS.get(group, GROUP_COLORS.get(source_str, GROUP_COLORS["é»˜è®¤"]))

    link_sources.append(node_id_map[source_str])
    link_targets.append(node_id_map[target_str])
    link_values.append(final_val)
    link_colors.append(final_color)
    link_customdata.append([source_str, target_str, original_val, ratio])

# èŠ‚ç‚¹é¢œè‰²
node_color_list = []
for node in all_nodes_sorted:
    if node in matched_nodes or not st.session_state.search_keyword or not st.session_state.search_keyword.strip():
        if node in GROUP_COLORS:
            node_color = GROUP_COLORS[node]
        elif "åˆä½œæ•°é‡" in node:
            platform = node.replace("åˆä½œæ•°é‡", "")
            node_color = GROUP_COLORS.get(platform, GROUP_COLORS["é»˜è®¤"])
        elif "clicks" in node:
            node_color = GROUP_COLORS.get("æ€»clicks", GROUP_COLORS["é»˜è®¤"])
        elif "orders" in node:
            node_color = GROUP_COLORS.get("æ€»orders", GROUP_COLORS["é»˜è®¤"])
        elif "sales" in node:
            node_color = GROUP_COLORS.get("æ€»sales", GROUP_COLORS["é»˜è®¤"])
        else:
            node_color = GROUP_COLORS.get(node, GROUP_COLORS["é»˜è®¤"])
    else:
        node_color = "rgba(200, 200, 200, 0.2)"
    node_color_list.append(node_color)

# ===================== 7. ç»˜åˆ¶æ¡‘åŸºå›¾ =====================
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=20,
        thickness=30,
        line=dict(color="black", width=1),
        label=all_nodes_sorted,
        color=node_color_list,
        hovertemplate="<b>%{label}</b><br>æµå…¥ï¼š%{customdata[0]:,.0f}<br>æµå‡ºï¼š%{customdata[1]:,.0f}<br>%{customdata[2]}<extra></extra>",
        customdata=node_customdata
    ),
    link=dict(
        source=link_sources,
        target=link_targets,
        value=link_values,
        color=link_colors,
        hovertemplate="<b>%{customdata[0]} â†’ %{customdata[1]}</b><br>åŸå§‹æ•°å€¼ï¼š%{customdata[2]:,.0f}<br>å %{customdata[1]}æ€»æµå…¥ï¼š%{customdata[3]:.2f}%<extra></extra>",
        customdata=link_customdata
    )
)])

# æ·»åŠ æ ‡é¢˜
title_text = "è”ç›Ÿè¥é”€å¹³å°è½¬åŒ–é“¾è·¯"
if st.session_state.search_keyword and st.session_state.search_keyword.strip():
    title_text += f" | æœç´¢ï¼š{st.session_state.search_keyword}"

fig.update_layout(
    title_text=title_text,
    font_size=12,
    autosize=True,
    font_color="pink",
    margin=dict(l=20, r=20, t=50, b=20),
    font=dict(family="Microsoft YaHei"),
    height=800
)

# æ˜¾ç¤ºå›¾è¡¨ - ä¿®å¤APIå¼ƒç”¨è­¦å‘Š
st.plotly_chart(fig, use_container_width=True, height=800)

# ===================== 8. æ•°æ®æ˜¾ç¤ºåŒºåŸŸ =====================
with st.expander("ğŸ“‹ æŸ¥çœ‹è¯¦ç»†æ•°æ®"):
    tab1, tab2, tab3 = st.tabs(["åŸå§‹æ•°æ®", "æ±‡æ€»æ•°æ®", "å¹³å°ç»Ÿè®¡"])
    
    with tab1:
        st.dataframe(df_sankey.head(100))
    
    with tab2:
        # æŒ‰å¹³å°æ±‡æ€»
        platform_summary = df_sankey.groupby("group").agg({
            "value": ["sum", "count"]
        }).round(2)
        platform_summary.columns = ["æ€»æ•°å€¼", "é“¾è·¯æ•°é‡"]
        st.dataframe(platform_summary)
    
    with tab3:
        # å¹³å°ç±»å‹ç»Ÿè®¡
        st.write(f"**å¹³å°ç±»å‹æ€»æ•°:** {len(platform_nodes)}")
        st.write(f"**åŒ¹é…çš„å¹³å°ç±»å‹:** {len(matched_platforms)}")
        
        if platform_nodes:
            st.write("**æ‰€æœ‰å¹³å°ç±»å‹:**")
            cols = st.columns(3)
            for i, platform in enumerate(platform_nodes):
                with cols[i % 3]:
                    st.write(f"â€¢ {platform}")

# ===================== 9. é¡µè„šä¿¡æ¯ =====================
st.markdown("---")
st.caption(f"ğŸ“… æ•°æ®æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
st.caption("ğŸ’¡ æç¤ºï¼šä¿®æ”¹Excelæ–‡ä»¶åï¼Œé‡æ–°ä¸Šä¼ å³å¯æ›´æ–°å›¾è¡¨")

# ===================== 10. æ­£ç¡®è¿è¡Œæ–¹å¼ =====================
# ä¸è¦åœ¨IDEä¸­ç›´æ¥è¿è¡Œè¿™ä¸ªæ–‡ä»¶
# ä½¿ç”¨å‘½ä»¤è¡Œï¼šstreamlit run sankeyyingxiao_streamlit.py